{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5033fe51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, World!\n"
     ]
    }
   ],
   "source": [
    "print('Hello, World!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2fa82e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a9b6f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Using device: cpu\n",
      "100%|██████████| 170M/170M [04:52<00:00, 583kB/s]  \n",
      "Training Epoch 1/10: 100%|██████████| 391/391 [03:08<00:00,  2.08it/s]\n",
      "INFO:__main__:Epoch 1, Loss: 1.5667, Accuracy: 0.4309\n",
      "Evaluating Epoch 1/10: 100%|██████████| 79/79 [00:31<00:00,  2.48it/s]\n",
      "INFO:__main__:Validation Loss: 1.3406, Accuracy: 0.5161\n",
      "Training Epoch 2/10: 100%|██████████| 391/391 [03:10<00:00,  2.06it/s]\n",
      "INFO:__main__:Epoch 2, Loss: 1.1887, Accuracy: 0.5756\n",
      "Evaluating Epoch 2/10: 100%|██████████| 79/79 [00:31<00:00,  2.52it/s]\n",
      "INFO:__main__:Validation Loss: 1.1340, Accuracy: 0.6062\n",
      "Training Epoch 3/10: 100%|██████████| 391/391 [03:06<00:00,  2.09it/s]\n",
      "INFO:__main__:Epoch 3, Loss: 1.0244, Accuracy: 0.6370\n",
      "Evaluating Epoch 3/10: 100%|██████████| 79/79 [00:30<00:00,  2.55it/s]\n",
      "INFO:__main__:Validation Loss: 0.9758, Accuracy: 0.6561\n",
      "Training Epoch 4/10: 100%|██████████| 391/391 [03:05<00:00,  2.11it/s]\n",
      "INFO:__main__:Epoch 4, Loss: 0.9329, Accuracy: 0.6703\n",
      "Evaluating Epoch 4/10: 100%|██████████| 79/79 [00:31<00:00,  2.55it/s]\n",
      "INFO:__main__:Validation Loss: 1.0121, Accuracy: 0.6499\n",
      "Training Epoch 5/10: 100%|██████████| 391/391 [03:06<00:00,  2.10it/s]\n",
      "INFO:__main__:Epoch 5, Loss: 0.8476, Accuracy: 0.7030\n",
      "Evaluating Epoch 5/10: 100%|██████████| 79/79 [00:31<00:00,  2.53it/s]\n",
      "INFO:__main__:Validation Loss: 0.9501, Accuracy: 0.6716\n",
      "Training Epoch 6/10: 100%|██████████| 391/391 [03:10<00:00,  2.05it/s]\n",
      "INFO:__main__:Epoch 6, Loss: 0.6884, Accuracy: 0.7580\n",
      "Evaluating Epoch 6/10: 100%|██████████| 79/79 [00:32<00:00,  2.46it/s]\n",
      "INFO:__main__:Validation Loss: 0.6976, Accuracy: 0.7563\n",
      "Training Epoch 7/10: 100%|██████████| 391/391 [03:08<00:00,  2.07it/s]\n",
      "INFO:__main__:Epoch 7, Loss: 0.6490, Accuracy: 0.7722\n",
      "Evaluating Epoch 7/10: 100%|██████████| 79/79 [00:31<00:00,  2.52it/s]\n",
      "INFO:__main__:Validation Loss: 0.6959, Accuracy: 0.7566\n",
      "Training Epoch 8/10: 100%|██████████| 391/391 [03:12<00:00,  2.03it/s]\n",
      "INFO:__main__:Epoch 8, Loss: 0.6313, Accuracy: 0.7792\n",
      "Evaluating Epoch 8/10: 100%|██████████| 79/79 [00:31<00:00,  2.51it/s]\n",
      "INFO:__main__:Validation Loss: 0.6704, Accuracy: 0.7641\n",
      "Training Epoch 9/10: 100%|██████████| 391/391 [03:20<00:00,  1.95it/s]\n",
      "INFO:__main__:Epoch 9, Loss: 0.6073, Accuracy: 0.7858\n",
      "Evaluating Epoch 9/10: 100%|██████████| 79/79 [00:33<00:00,  2.33it/s]\n",
      "INFO:__main__:Validation Loss: 0.6727, Accuracy: 0.7655\n",
      "Training Epoch 10/10: 100%|██████████| 391/391 [03:24<00:00,  1.91it/s]\n",
      "INFO:__main__:Epoch 10, Loss: 0.5937, Accuracy: 0.7916\n",
      "Evaluating Epoch 10/10: 100%|██████████| 79/79 [00:33<00:00,  2.35it/s]\n",
      "INFO:__main__:Validation Loss: 0.6646, Accuracy: 0.7664\n",
      "INFO:__main__:Training complete in 37.25 minutes\n"
     ]
    }
   ],
   "source": [
    "# Sample deep learning network using PyTorch to test environment\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.models import resnet18\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "# Set random seeds for reproducibility\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "set_seed(42)\n",
    "# Check device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logger.info(f'Using device: {device}')\n",
    "# Hyperparameters\n",
    "batch_size = 128\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "# Data preparation\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "train_dataset = CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "# Model, loss function, optimizer, scheduler\n",
    "model = resnet18(pretrained=False, num_classes=10).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "# TensorBoard setup\n",
    "log_dir = './logs'\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "# Training and evaluation functions\n",
    "def train_one_epoch(epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    for inputs, labels in tqdm(train_loader, desc=f'Training Epoch {epoch+1}/{num_epochs}'):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    epoch_acc = accuracy_score(all_labels, all_preds)\n",
    "    logger.info(f'Epoch {epoch+1}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}')\n",
    "    writer.add_scalar('Train/Loss', epoch_loss, epoch)\n",
    "    writer.add_scalar('Train/Accuracy', epoch_acc, epoch)\n",
    "\n",
    "def evaluate(epoch):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(test_loader, desc=f'Evaluating Epoch {epoch+1}/{num_epochs}'):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    epoch_loss = running_loss / len(test_loader.dataset)\n",
    "    epoch_acc = accuracy_score(all_labels, all_preds)\n",
    "    logger.info(f'Validation Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}')\n",
    "    writer.add_scalar('Val/Loss', epoch_loss, epoch)\n",
    "    writer.add_scalar('Val/Accuracy', epoch_acc, epoch)\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    cm_df = pd.DataFrame(cm, index=train_dataset.classes, columns=train_dataset.classes)\n",
    "    plt.figure(figsize=(10,8))\n",
    "    sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.title(f'Confusion Matrix Epoch {epoch+1}')\n",
    "    cm_path = os.path.join(log_dir, f'confusion_matrix_epoch_{epoch+1}.png')\n",
    "    plt.savefig(cm_path)\n",
    "    plt.close()\n",
    "    writer.add_image('Confusion_Matrix', plt.imread(cm_path), epoch, dataformats='HWC')\n",
    "# Main training loop\n",
    "start_time = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    train_one_epoch(epoch)\n",
    "    evaluate(epoch)\n",
    "    scheduler.step()\n",
    "end_time = time.time()\n",
    "logger.info(f'Training complete in {(end_time - start_time)/60:.2f} minutes')\n",
    "# Save the model\n",
    "model_path = './resnet18_cifar10.pth'\n",
    "torch.save(model.state_dict(), model_path)\n",
    "# Close the TensorBoard writer\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cca4cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GenAI-Applications (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
